{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "114cf9c2",
   "metadata": {},
   "source": [
    "# DSCI 525 - Web and Cloud Computing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcfdb0d",
   "metadata": {},
   "source": [
    "Milestone 2: Your team is planning to migrate to the cloud. AWS gave 400$ (100$ each) to your team to support this. As part of this initiative, your team needs to set up a server in the cloud, a collaborative environment for your team, and later move your data to the cloud. After that, your team can wrangle the data in preparation for machine learning.\n",
    "\n",
    "## Milestone 2 checklist  \n",
    "You will have mainly 2 tasks. Here is the checklist...\n",
    "- Task 1: To set up a collaborative environment \n",
    "    - Setup your EC2 instance with JupyterHub.\n",
    "    - Install all necessary things needed in your UNIX server (Amazon EC2 instance).\n",
    "    - Set up your S3 bucket.\n",
    "    - Move the data that you wrangled in your last milestone to S3.\n",
    "- Task 2: Wrangle the data in preparation for machine learning\n",
    "    - Get the data from S3 in your notebook and make data ready for machine learning.\n",
    "\n",
    "> Everything in this milestone is to be completed in sequential order. But if you want to divide the tasks, you can ask a team member to work on Task 2 (```4. Get the data that we wrangled in our first milestone.``` and ```6. Wrangle the data in preparation for machine learning```) locally on their laptop while the other members set up the infrastructure (EC2, S3) and TLJH in the cloud. This way, you can move quick.\n",
    "\n",
    "_***Outside of Milestone:*** I strongly recommend you spin up your own instance and experiment with the s3 bucket in doing something (there are many things that we learned and practical work from video series) to get comfortable with AWS. But we won't be looking at it for a grading purpose._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6849a9a",
   "metadata": {},
   "source": [
    "**Keep in mind:**\n",
    "\n",
    "- _All services you use are in region ```us-west-2```._\n",
    "\n",
    "- _Don't store anything in these servers or storage that represents your identity as a student (like your student ID number) ._\n",
    "\n",
    "- _Use only default VPC and subnet._\n",
    "    \n",
    "- _No IP addresses are visible when you provide the screenshot._\n",
    "\n",
    "- _You do proper budgeting so that you don't run out of credits._ \n",
    "\n",
    "- _We want one single notebook for grading, and it's up to your discretion on how you do it. ***So only one person in your group needs to spin up instance and a ```t2.large``` is of decent size.***_\n",
    "\n",
    "- _Please stop the instance when not in use. This can save you some bucks, but it's again up to you and how you budget your money. Maybe stop it if you or your team won't use it for the next 5 hours?_\n",
    "\n",
    "- _Your AWS lab will shut down after 4 hours (also your services). When you start it again (after it is stopped), your AWS credentials (***access key***,***secret***, and ***session token***) will change, and you want to update your credentials file with the new one._\n",
    "\n",
    "- _If you don't want your lab to shut down, click on the start lab again before 4 hours ends. This will fill up your time to 4 hours._\n",
    "\n",
    "- _Say something went wrong and you want to spin up another EC2 instance, then it will be good to terminate the previous one._\n",
    "\n",
    "- _We will be choosing the storage to be ```Delete on Termination``` ( that is the default option), which means that stored data in your instance will be lost upon termination. Make sure you save any data to S3 and download the notebooks to your laptop so that next time you have your jupyterHub in a different instance, you can upload your notebook there._\n",
    "\n",
    "- _Wherever I ask for screenshots, you can provide the screenshot location in your GitHub._\n",
    "\n",
    "***NOTE:*** Everything you want for this notebook is discussed in lecture 3 and lecture 4. So you can follow the same order of things shown in lecture 4. You can also refer to the videos linked in each section under image ![YouTube](https://cdn.emojidex.com/emoji/hdpi/YouTube.png \"YouTube\") to see a demo on how to do it. In addition, I will put a link to the lecture note section that applies to each question in this milestone so that you don't get lost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1884cb4",
   "metadata": {},
   "source": [
    "### 1. Setup your EC2 instance\n",
    "- Name of the instance to be `mds-your_groupnumber`. For example if my group is 14 I would name it `mds-14`.\n",
    "- AMI to be `Ubuntu server 22.04 LTS (HVM)`.\n",
    "- Instance type to be `t2.large`.\n",
    "- Architecture to be `64-bit(x86)`.\n",
    "- Storage to be `30 GB`.\n",
    "- Make sure you install TLJH in your instance, by giving instructions in `User Data`.\n",
    "\n",
    "> Check [this](https://pages.github.ubc.ca/MDS-2022-23/DSCI_525_web-cloud-comp_students/lectures/lecture4.html#setting-up-an-ec2-instance) section in lecture notes for more details on setting up EC2 instance with TLJH."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e80c45",
   "metadata": {},
   "source": [
    "rubric={correctness:20}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82539b2",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"image/1_result.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9801b911",
   "metadata": {},
   "source": [
    "### 2. Setup the server \n",
    "\n",
    "rubric={correctness:20}\n",
    "\n",
    "2.1) Add your team members to EC2 instance.\n",
    "\n",
    "2.2) Setup a common data folder to download data, and this folder should be accessible by all users in the JupyterHub.\n",
    "    \n",
    "2.3) Install and configure AWS CLI.\n",
    "\n",
    "> Check following sections in lecture notes for more details;\n",
    "\n",
    "- [Logging into EC2s](https://pages.github.ubc.ca/MDS-2022-23/DSCI_525_web-cloud-comp_students/lectures/lecture4.html#logging-into-ec2)\n",
    "- [Setting up a common space in EC2](https://pages.github.ubc.ca/MDS-2022-23/DSCI_525_web-cloud-comp_students/lectures/lecture4.html#setting-up-a-common-space-in-ec2) \n",
    "- [AWS CLI](https://pages.github.ubc.ca/MDS-2022-23/DSCI_525_web-cloud-comp_students/lectures/lecture3.html#aws-cli)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c732ef2d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<img src=\"image/2_result.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539ad5a3",
   "metadata": {},
   "source": [
    "### 3. Setup your JupyterHub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639f8283",
   "metadata": {},
   "source": [
    "rubric={correctness:20}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dea6704",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<img src=\"image/3_result.png\" >\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeecde21",
   "metadata": {},
   "source": [
    "### 4. Get the data what we wrangled in our first milestone. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2174bec3",
   "metadata": {},
   "source": [
    "You have to install the packages that are needed. Refer this TLJH [document]( https://tljh.jupyter.org/en/latest/howto/env/user-environment.html).Refer ```pip``` section.\n",
    "\n",
    "Don't forget to add option -E. This way, all packages that you install will be available to other users in your JupyterHub.\n",
    "These packages you must install and install other packages needed for your wrangling.\n",
    "\n",
    "    sudo -E pip install pandas\n",
    "    sudo -E pip install pyarrow\n",
    "    sudo -E pip install s3fs\n",
    "\n",
    "> Check [this](https://pages.github.ubc.ca/MDS-2022-23/DSCI_525_web-cloud-comp_students/lectures/lecture4.html#how-to-install-packages-in-tljh) section in lecture notes for more details on installing packages in TLJH."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d32fbd",
   "metadata": {},
   "source": [
    "As in the last milestone, we looked at transferring the data from Python to R, and we have different solutions. To stay consistent, I uploaded the parquet file (which I combined and converted in the last milestone), which we can use moving forward. Here in this section, I am getting that file using API; (the section is prepopulated for you)\n",
    "\n",
    "Remember, from now on, we are going to run this notebook in the TLJH that is set up from previous steps. You can upload your notebook there using the upload button in jupyter. After that, you are going to run the following code to get the data downloaded to your EC2 instance and then you move to questions 5 and 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec6a16f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "import requests\n",
    "from urllib.request import urlretrieve\n",
    "import json\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9a0658a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"AWS_SHARED_CREDENTIALS_FILE\"] = \"/srv/keys/credentials\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b16325",
   "metadata": {},
   "source": [
    "Rememeber here we gave the folder that we created in Step 2.2 as we made it available for all the users in a group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07bd98c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#    Necessary metadata\n",
    "# article_id = 14226968  # this is the unique identifier of the article on figshare\n",
    "# url = f\"https://api.figshare.com/v2/articles/{article_id}\"\n",
    "# headers = {\"Content-Type\": \"application/json\"}\n",
    "# output_directory = \"/srv/data/my_shared_data_folder/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9dae876e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = requests.request(\"GET\", url, headers=headers)\n",
    "# data = json.loads(response.text)  # this contains all the articles data, feel free to check it out\n",
    "# files = data[\"files\"]             # this is just the data about the files, which is what we want\n",
    "# files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70060372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# files_to_dl = [\"combined_model_data_parti.parquet.zip\"]  ## Please download the partitioned \n",
    "# for file in files:\n",
    "#     if file[\"name\"] in files_to_dl:\n",
    "#         os.makedirs(output_directory, exist_ok=True)\n",
    "#         urlretrieve(file[\"download_url\"], output_directory + file[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11642663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with zipfile.ZipFile(os.path.join(output_directory, \"combined_model_data_parti.parquet.zip\"), 'r') as f:\n",
    "#     f.extractall(output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2f04d9",
   "metadata": {},
   "source": [
    "### 5. Setup your S3 bucket and move data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9c2bbf",
   "metadata": {},
   "source": [
    "rubric={correctness:15}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc337efd",
   "metadata": {},
   "source": [
    "> Check [this](https://pages.github.ubc.ca/MDS-2022-23/DSCI_525_web-cloud-comp_students/lectures/lecture4.html#setting-up-s3-bucket) section in lecture notes for more details on setting up S3 bucket and ***making it public***. \n",
    "\n",
    "5.1)  Create a bucket and name should be mds-s3-groupnumber-studentname. Replace groupnumber with your \"group number\", and studentname with your \"student name\". For example, if my group is 14 and my name is \"Gittu George\", then I would name it \"mds-s3-14-gittu\". (Note: For the purpose of this milestone only one student need to create this.)\n",
    "\n",
    "5.2)  Create your first folder called \"output\".\n",
    "\n",
    "5.3) Move the \"observed_daily_rainfall_SYD.csv\" file from the Milestone1 data folder to your s3 bucket from your local computer.\n",
    "\n",
    "5.4) Moving the parquet file we downloaded(combined_model_data_parti.parquet) in step 4 to S3 using the cli what we installed in step 2.3.\n",
    "\n",
    "\n",
    "> Check [this](https://pages.github.ubc.ca/MDS-2022-23/DSCI_525_web-cloud-comp_students/lectures/lecture4.html#how-to-transfer-data-to-s3) section in lecture notes for more details on moving data to S3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d3e08c",
   "metadata": {},
   "source": [
    "#### Please provide here the GitHub path to your screenshot for grading. Example screenshot below;\n",
    "\n",
    "Make sure it has 3 objects and see red `public` symbol in your bucket. Refer below screenshot for reference.\n",
    "\n",
    "<img src=\"image/4_result.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d40246",
   "metadata": {},
   "source": [
    "### 6. Wrangle the data in preparation for machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683ca7b4",
   "metadata": {},
   "source": [
    "rubric={correctness:20}\n",
    "\n",
    "> ***IMPORTANT:*** Don't forget to deal with the credentials before you start this section. Check details in lecture notes [here](https://pages.github.ubc.ca/MDS-2022-23/DSCI_525_web-cloud-comp_students/lectures/lecture4.html#more-about-credentials)\n",
    "\n",
    "> Check [this](https://pages.github.ubc.ca/MDS-2022-23/DSCI_525_web-cloud-comp_students/lectures/lecture4.html#how-to-read-data-from-s3) section in lecture notes for more details on how to read data from S3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f1fca0",
   "metadata": {},
   "source": [
    "Our data currently covers all of NSW, but say that our client wants us to create a machine learning model to predict rainfall over Sydney only. There's a bit of wrangling that needs to be done for that:\n",
    "1. We need to query our data for only the rows that contain information covering Sydney\n",
    "2. We need to wrangle our data into a format suitable for training a machine learning model. That will require pivoting, resampling, grouping, etc.\n",
    "\n",
    "To train an ML algorithm we need it to look like this:\n",
    "\n",
    "||model-1_rainfall|model-2_rainfall|model-3_rainfall|...|observed_rainfall|\n",
    "|---|---|---|---|---|---|\n",
    "|0|0.12|0.43|0.35|...|0.31|\n",
    "|1|1.22|0.91|1.68|...|1.34|\n",
    "|2|0.68|0.29|0.41|...|0.57|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b4929d",
   "metadata": {},
   "source": [
    "6.1) Get the data from s3 (```combined_model_data_parti.parquet``` and ```observed_daily_rainfall_SYD.csv```)\n",
    "\n",
    "6.2) First query for Sydney data and then drop the lat and lon columns (we don't need them).\n",
    "```\n",
    "syd_lat = -33.86\n",
    "syd_lon = 151.21\n",
    "```\n",
    "Expected shape ```(1150049, 2)```.\n",
    "\n",
    "6.3) Save this processed file to s3 for later use:\n",
    "\n",
    "  Save as a csv file ```ml_data_SYD.csv``` to ```s3://mds-s3-xxx/output/```\n",
    "  expected shape ```(46020,26)``` - This includes all the models as columns and also adding additional column ```Observed``` loaded from ```observed_daily_rainfall_SYD.csv``` from s3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a4a82b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04d572df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rain (mm/day)</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1889-01-01</th>\n",
       "      <td>0.040427</td>\n",
       "      <td>ACCESS-CM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889-01-02</th>\n",
       "      <td>0.073777</td>\n",
       "      <td>ACCESS-CM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889-01-03</th>\n",
       "      <td>0.232656</td>\n",
       "      <td>ACCESS-CM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889-01-04</th>\n",
       "      <td>0.911319</td>\n",
       "      <td>ACCESS-CM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889-01-05</th>\n",
       "      <td>0.698013</td>\n",
       "      <td>ACCESS-CM2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rain (mm/day)       model\n",
       "time                                 \n",
       "1889-01-01       0.040427  ACCESS-CM2\n",
       "1889-01-02       0.073777  ACCESS-CM2\n",
       "1889-01-03       0.232656  ACCESS-CM2\n",
       "1889-01-04       0.911319  ACCESS-CM2\n",
       "1889-01-05       0.698013  ACCESS-CM2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Do all your coding here\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "import urllib.parse\n",
    "\n",
    "# Filter sydney data\n",
    "syd_lat = -33.86\n",
    "syd_lon = 151.21\n",
    "aws_credentials ={\"key\": \"ASIAT7ZIBXUSOHNMB7T2\",\"secret\": \"oZz8xmpWwN4s5CFBNGBRzUh6sncfcIZth2UV1/b6\",\n",
    "                  \"token\":\"FwoGZXIvYXdzEGEaDLOIHVkGHZVPvfld5yLHAViUXHr2bWRmjMkiH4qaM+N/RFAx81K+TOxmgJKIPnkRFYh7HQ86XarEdx4cYx/GSR0MLuCcJEethZimna9HFMyO3SSrooEkgmiWzCaSeqzmEwratJ2bUGS/+0QkGR6fdBsNLgVa+M833NdyUToi25pvzwLCysz3GtOfk8dmfvCHtWJ1Frzt9gSOZrxYLdbAU1ePcmiaXom9Yn2CB6EOBZyYwZBYSCU8Isiy6GM0ZeiaeZX79uz8sHqUgqvqMrPJGcAQVQRFGQMo86m9oQYyLYqzbUQFQ32bbJaSKuKSW6qVfX72qrg2r0hyv8qbnE2VxPTXzhk3IiRpYfeMmg==\"}\n",
    "\n",
    "df_model = pd.read_parquet(\"s3://mds-s3-13-vincent/combined_model_data_parti.parquet/\", \n",
    "                    filters=[('lat_min','<', syd_lat), ('lat_max','>', syd_lat),\n",
    "                             ('lon_min','<', syd_lon), ('lon_max','>', syd_lon)],\n",
    "                    columns=['time', 'rain (mm/day)', 'model']\n",
    "                    , storage_options=aws_credentials \n",
    "                    )\n",
    "df_model['time'] = pd.to_datetime(df_model['time']).dt.date\n",
    "df_model = df_model.set_index('time')\n",
    "df_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6afb3207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46020, 25)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pivot longer \n",
    "df_model = df_model.pivot_table(index='time', columns='model', values='rain (mm/day)')\n",
    "df_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bbbe6d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rain (mm/day)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1889-01-01</th>\n",
       "      <td>0.006612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889-01-02</th>\n",
       "      <td>0.090422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889-01-03</th>\n",
       "      <td>1.401452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889-01-04</th>\n",
       "      <td>14.869798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889-01-05</th>\n",
       "      <td>0.467628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rain (mm/day)\n",
       "time                     \n",
       "1889-01-01       0.006612\n",
       "1889-01-02       0.090422\n",
       "1889-01-03       1.401452\n",
       "1889-01-04      14.869798\n",
       "1889-01-05       0.467628"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join observed data to the dataframe\n",
    "df_obs = pd.read_csv('s3://mds-s3-13-vincent/observed_daily_rainfall_SYD.csv', storage_options=aws_credentials)\n",
    "df_obs['time'] = pd.to_datetime(df_obs['time']).dt.date\n",
    "df_obs = df_obs.set_index('time')\n",
    "df_obs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2c5abe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46020, 26)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add the observed column\n",
    "df_model['observed'] = df_obs['rain (mm/day)']\n",
    "df_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "36b769ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>model</th>\n",
       "      <th>ACCESS-CM2</th>\n",
       "      <th>ACCESS-ESM1-5</th>\n",
       "      <th>AWI-ESM-1-1-LR</th>\n",
       "      <th>BCC-CSM2-MR</th>\n",
       "      <th>BCC-ESM1</th>\n",
       "      <th>CMCC-CM2-HR4</th>\n",
       "      <th>CMCC-CM2-SR5</th>\n",
       "      <th>CMCC-ESM2</th>\n",
       "      <th>CanESM5</th>\n",
       "      <th>EC-Earth3-Veg-LR</th>\n",
       "      <th>...</th>\n",
       "      <th>MPI-ESM-1-2-HAM</th>\n",
       "      <th>MPI-ESM1-2-HR</th>\n",
       "      <th>MPI-ESM1-2-LR</th>\n",
       "      <th>MRI-ESM2-0</th>\n",
       "      <th>NESM3</th>\n",
       "      <th>NorESM2-LM</th>\n",
       "      <th>NorESM2-MM</th>\n",
       "      <th>SAM0-UNICON</th>\n",
       "      <th>TaiESM1</th>\n",
       "      <th>observed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1889-01-01</th>\n",
       "      <td>0.040427</td>\n",
       "      <td>1.814552</td>\n",
       "      <td>35.579336</td>\n",
       "      <td>4.268112e+00</td>\n",
       "      <td>1.107466e-03</td>\n",
       "      <td>11.410537</td>\n",
       "      <td>3.322009e-08</td>\n",
       "      <td>2.668800</td>\n",
       "      <td>1.321215</td>\n",
       "      <td>1.515293</td>\n",
       "      <td>...</td>\n",
       "      <td>4.244226e-13</td>\n",
       "      <td>1.390174e-13</td>\n",
       "      <td>6.537884e-05</td>\n",
       "      <td>3.445495e-06</td>\n",
       "      <td>1.576096e+01</td>\n",
       "      <td>4.759651e-05</td>\n",
       "      <td>2.451075</td>\n",
       "      <td>0.221324</td>\n",
       "      <td>2.257933</td>\n",
       "      <td>0.006612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889-01-02</th>\n",
       "      <td>0.073777</td>\n",
       "      <td>0.303965</td>\n",
       "      <td>4.596520</td>\n",
       "      <td>1.190141e+00</td>\n",
       "      <td>1.015323e-04</td>\n",
       "      <td>4.014984</td>\n",
       "      <td>1.312700e+00</td>\n",
       "      <td>0.946211</td>\n",
       "      <td>2.788724</td>\n",
       "      <td>4.771375</td>\n",
       "      <td>...</td>\n",
       "      <td>4.409552e+00</td>\n",
       "      <td>1.222283e-01</td>\n",
       "      <td>1.049131e-13</td>\n",
       "      <td>4.791993e-09</td>\n",
       "      <td>3.675510e-01</td>\n",
       "      <td>4.350863e-01</td>\n",
       "      <td>0.477231</td>\n",
       "      <td>3.757179</td>\n",
       "      <td>2.287381</td>\n",
       "      <td>0.090422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889-01-03</th>\n",
       "      <td>0.232656</td>\n",
       "      <td>0.019976</td>\n",
       "      <td>5.927467</td>\n",
       "      <td>1.003845e-09</td>\n",
       "      <td>1.760345e-05</td>\n",
       "      <td>9.660565</td>\n",
       "      <td>9.103720e+00</td>\n",
       "      <td>0.431999</td>\n",
       "      <td>0.003672</td>\n",
       "      <td>4.233980</td>\n",
       "      <td>...</td>\n",
       "      <td>2.269300e-01</td>\n",
       "      <td>3.762301e-01</td>\n",
       "      <td>9.758706e-14</td>\n",
       "      <td>6.912302e-01</td>\n",
       "      <td>1.562869e-01</td>\n",
       "      <td>9.561101e+00</td>\n",
       "      <td>0.023083</td>\n",
       "      <td>0.253357</td>\n",
       "      <td>1.199909</td>\n",
       "      <td>1.401452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889-01-04</th>\n",
       "      <td>0.911319</td>\n",
       "      <td>13.623777</td>\n",
       "      <td>8.029624</td>\n",
       "      <td>8.225225e-02</td>\n",
       "      <td>1.808932e-01</td>\n",
       "      <td>3.951528</td>\n",
       "      <td>1.317160e+01</td>\n",
       "      <td>0.368693</td>\n",
       "      <td>0.013578</td>\n",
       "      <td>15.252495</td>\n",
       "      <td>...</td>\n",
       "      <td>2.344586e-02</td>\n",
       "      <td>4.214019e-01</td>\n",
       "      <td>7.060915e-03</td>\n",
       "      <td>3.835721e-02</td>\n",
       "      <td>2.472226e-07</td>\n",
       "      <td>5.301038e-01</td>\n",
       "      <td>0.002699</td>\n",
       "      <td>2.185454</td>\n",
       "      <td>2.106737</td>\n",
       "      <td>14.869798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889-01-05</th>\n",
       "      <td>0.698013</td>\n",
       "      <td>0.021048</td>\n",
       "      <td>2.132686</td>\n",
       "      <td>2.496841e+00</td>\n",
       "      <td>4.708019e-09</td>\n",
       "      <td>2.766362</td>\n",
       "      <td>1.822940e+01</td>\n",
       "      <td>0.339267</td>\n",
       "      <td>0.002468</td>\n",
       "      <td>11.920356</td>\n",
       "      <td>...</td>\n",
       "      <td>4.270161e-13</td>\n",
       "      <td>1.879692e-01</td>\n",
       "      <td>4.504985e+00</td>\n",
       "      <td>3.506923e-07</td>\n",
       "      <td>1.949792e-13</td>\n",
       "      <td>1.460928e-10</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>2.766507</td>\n",
       "      <td>1.763335</td>\n",
       "      <td>0.467628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "model       ACCESS-CM2  ACCESS-ESM1-5  AWI-ESM-1-1-LR   BCC-CSM2-MR   \n",
       "time                                                                  \n",
       "1889-01-01    0.040427       1.814552       35.579336  4.268112e+00  \\\n",
       "1889-01-02    0.073777       0.303965        4.596520  1.190141e+00   \n",
       "1889-01-03    0.232656       0.019976        5.927467  1.003845e-09   \n",
       "1889-01-04    0.911319      13.623777        8.029624  8.225225e-02   \n",
       "1889-01-05    0.698013       0.021048        2.132686  2.496841e+00   \n",
       "\n",
       "model           BCC-ESM1  CMCC-CM2-HR4  CMCC-CM2-SR5  CMCC-ESM2   CanESM5   \n",
       "time                                                                        \n",
       "1889-01-01  1.107466e-03     11.410537  3.322009e-08   2.668800  1.321215  \\\n",
       "1889-01-02  1.015323e-04      4.014984  1.312700e+00   0.946211  2.788724   \n",
       "1889-01-03  1.760345e-05      9.660565  9.103720e+00   0.431999  0.003672   \n",
       "1889-01-04  1.808932e-01      3.951528  1.317160e+01   0.368693  0.013578   \n",
       "1889-01-05  4.708019e-09      2.766362  1.822940e+01   0.339267  0.002468   \n",
       "\n",
       "model       EC-Earth3-Veg-LR  ...  MPI-ESM-1-2-HAM  MPI-ESM1-2-HR   \n",
       "time                          ...                                   \n",
       "1889-01-01          1.515293  ...     4.244226e-13   1.390174e-13  \\\n",
       "1889-01-02          4.771375  ...     4.409552e+00   1.222283e-01   \n",
       "1889-01-03          4.233980  ...     2.269300e-01   3.762301e-01   \n",
       "1889-01-04         15.252495  ...     2.344586e-02   4.214019e-01   \n",
       "1889-01-05         11.920356  ...     4.270161e-13   1.879692e-01   \n",
       "\n",
       "model       MPI-ESM1-2-LR    MRI-ESM2-0         NESM3    NorESM2-LM   \n",
       "time                                                                  \n",
       "1889-01-01   6.537884e-05  3.445495e-06  1.576096e+01  4.759651e-05  \\\n",
       "1889-01-02   1.049131e-13  4.791993e-09  3.675510e-01  4.350863e-01   \n",
       "1889-01-03   9.758706e-14  6.912302e-01  1.562869e-01  9.561101e+00   \n",
       "1889-01-04   7.060915e-03  3.835721e-02  2.472226e-07  5.301038e-01   \n",
       "1889-01-05   4.504985e+00  3.506923e-07  1.949792e-13  1.460928e-10   \n",
       "\n",
       "model       NorESM2-MM  SAM0-UNICON   TaiESM1   observed  \n",
       "time                                                      \n",
       "1889-01-01    2.451075     0.221324  2.257933   0.006612  \n",
       "1889-01-02    0.477231     3.757179  2.287381   0.090422  \n",
       "1889-01-03    0.023083     0.253357  1.199909   1.401452  \n",
       "1889-01-04    0.002699     2.185454  2.106737  14.869798  \n",
       "1889-01-05    0.001026     2.766507  1.763335   0.467628  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b98047ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "Anonymous users cannot initiate multipart uploads.  Please authenticate.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.9/site-packages/s3fs/core.py:112\u001b[0m, in \u001b[0;36m_error_wrapper\u001b[0;34m(func, args, kwargs, retries)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m S3_RETRYABLE_ERRORS \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.9/site-packages/aiobotocore/client.py:358\u001b[0m, in \u001b[0;36mAioBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    357\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m--> 358\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (AccessDenied) when calling the CreateMultipartUpload operation: Anonymous users cannot initiate multipart uploads.  Please authenticate.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Save the processed file to s3 for later use\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mdf_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ms3://mds-s3-13-vincent/output/ml_data_SYD.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.9/site-packages/pandas/core/generic.py:3772\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3761\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3763\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3764\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3765\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3769\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3770\u001b[0m )\n\u001b[0;32m-> 3772\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3775\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3777\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3779\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3789\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.9/site-packages/pandas/io/formats/format.py:1186\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1165\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1167\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m   1168\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m   1169\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1184\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1185\u001b[0m )\n\u001b[0;32m-> 1186\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1189\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.9/site-packages/pandas/io/formats/csvs.py:259\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    250\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    251\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    256\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    257\u001b[0m     )\n\u001b[0;32m--> 259\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.9/site-packages/pandas/io/formats/csvs.py:264\u001b[0m, in \u001b[0;36mCSVFormatter._save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_need_to_save_header:\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_header()\n\u001b[0;32m--> 264\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.9/site-packages/pandas/io/formats/csvs.py:302\u001b[0m, in \u001b[0;36mCSVFormatter._save_body\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m end_i:\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 302\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_i\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.9/site-packages/pandas/io/formats/csvs.py:313\u001b[0m, in \u001b[0;36mCSVFormatter._save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m    310\u001b[0m data \u001b[38;5;241m=\u001b[39m [res\u001b[38;5;241m.\u001b[39miget_values(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(res\u001b[38;5;241m.\u001b[39mitems))]\n\u001b[1;32m    312\u001b[0m ix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_index[slicer]\u001b[38;5;241m.\u001b[39m_format_native_types(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_number_format)\n\u001b[0;32m--> 313\u001b[0m \u001b[43mlibwriters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_csv_rows\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43mix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.9/site-packages/pandas/_libs/writers.pyx:55\u001b[0m, in \u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.9/site-packages/fsspec/spec.py:1616\u001b[0m, in \u001b[0;36mAbstractBufferedFile.write\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1614\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m out\n\u001b[1;32m   1615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer\u001b[38;5;241m.\u001b[39mtell() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocksize:\n\u001b[0;32m-> 1616\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1617\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.9/site-packages/fsspec/spec.py:1652\u001b[0m, in \u001b[0;36mAbstractBufferedFile.flush\u001b[0;34m(self, force)\u001b[0m\n\u001b[1;32m   1650\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moffset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1651\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1652\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initiate_upload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:  \u001b[38;5;66;03m# noqa: E722\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclosed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.9/site-packages/s3fs/core.py:2090\u001b[0m, in \u001b[0;36mS3File._initiate_upload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2088\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitiate upload for \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   2089\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparts \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 2090\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmpu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_s3\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2091\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcreate_multipart_upload\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2092\u001b[0m \u001b[43m    \u001b[49m\u001b[43mBucket\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbucket\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2093\u001b[0m \u001b[43m    \u001b[49m\u001b[43mKey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2094\u001b[0m \u001b[43m    \u001b[49m\u001b[43mACL\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2095\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2097\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mappend_block:\n\u001b[1;32m   2098\u001b[0m     \u001b[38;5;66;03m# use existing data in key when appending,\u001b[39;00m\n\u001b[1;32m   2099\u001b[0m     \u001b[38;5;66;03m# and block is big enough\u001b[39;00m\n\u001b[1;32m   2100\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_s3(\n\u001b[1;32m   2101\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupload_part_copy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2102\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ms3_additional_kwargs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2107\u001b[0m         CopySource\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath,\n\u001b[1;32m   2108\u001b[0m     )\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.9/site-packages/s3fs/core.py:2082\u001b[0m, in \u001b[0;36mS3File._call_s3\u001b[0;34m(self, method, *kwarglist, **kwargs)\u001b[0m\n\u001b[1;32m   2081\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_s3\u001b[39m(\u001b[38;5;28mself\u001b[39m, method, \u001b[38;5;241m*\u001b[39mkwarglist, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 2082\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_s3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ms3_additional_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwarglist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.9/site-packages/fsspec/asyn.py:115\u001b[0m, in \u001b[0;36msync_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m obj \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.9/site-packages/fsspec/asyn.py:100\u001b[0m, in \u001b[0;36msync\u001b[0;34m(loop, func, timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FSTimeoutError \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreturn_result\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(return_result, \u001b[38;5;167;01mBaseException\u001b[39;00m):\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m return_result\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m return_result\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.9/site-packages/fsspec/asyn.py:55\u001b[0m, in \u001b[0;36m_runner\u001b[0;34m(event, coro, result, timeout)\u001b[0m\n\u001b[1;32m     53\u001b[0m     coro \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mwait_for(coro, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 55\u001b[0m     result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m coro\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m     57\u001b[0m     result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m ex\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.9/site-packages/s3fs/core.py:347\u001b[0m, in \u001b[0;36mS3FileSystem._call_s3\u001b[0;34m(self, method, *akwarglist, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCALL: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, akwarglist, kw2)\n\u001b[1;32m    346\u001b[0m additional_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_s3_method_kwargs(method, \u001b[38;5;241m*\u001b[39makwarglist, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m _error_wrapper(\n\u001b[1;32m    348\u001b[0m     method, kwargs\u001b[38;5;241m=\u001b[39madditional_kwargs, retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretries\n\u001b[1;32m    349\u001b[0m )\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.9/site-packages/s3fs/core.py:139\u001b[0m, in \u001b[0;36m_error_wrapper\u001b[0;34m(func, args, kwargs, retries)\u001b[0m\n\u001b[1;32m    137\u001b[0m         err \u001b[38;5;241m=\u001b[39m e\n\u001b[1;32m    138\u001b[0m err \u001b[38;5;241m=\u001b[39m translate_boto_error(err)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m err\n",
      "\u001b[0;31mPermissionError\u001b[0m: Anonymous users cannot initiate multipart uploads.  Please authenticate."
     ]
    }
   ],
   "source": [
    "# Save the processed file to s3 for later use\n",
    "\n",
    "df_model.to_csv(\"s3://mds-s3-13-vincent/output/ml_data_SYD.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7604964",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "f75bc37be52f1a54b499f2bd249d6269a196b34b202e3f84ac376713198385a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
